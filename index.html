<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="./favicon.png" />
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link href="https://fonts.googleapis.com/css2?family=Jersey+10&display=swap" rel="stylesheet" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Transformer Explainer: LLM Transformer Model Visually Explained</title>

		<!-- Primary Meta Tags -->
		<meta name="title" content="Transformer Explainer: LLM Transformer Model Visually Explained" />
		<meta
			name="description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>

		<!-- Open Graph / Facebook -->
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="og:title"
			content="Transformer Explainer: LLM Transformer Model Visually Explained"
		/>
		<meta
			property="og:description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>
		<meta
			property="og:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		<!-- Twitter -->
		<meta property="twitter:card" content="summary_large_image" />
		<meta property="twitter:url" content="https://poloclub.github.io/transformer-explainer/" />
		<meta
			property="twitter:title"
			content="Transformer Explainer: LLM Transformer Model Visually Explained"
		/>
		<meta
			property="twitter:description"
			content="An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT."
		/>
		<meta
			property="twitter:image"
			content="https://poloclub.github.io/transformer-explainer/preview/summary.png"
		/>

		
		<link href="./_app/immutable/assets/Katex.CbsiBf5l.css" rel="stylesheet">
		<link href="./_app/immutable/assets/0.C0jsMVhS.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.D8EW9tW5.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.BVZbiFrz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DwuQy57r.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/mTJAjmXP.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BvrDaLBj.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.B8GfoBYF.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/IHki7fMi.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.BcgzoSZv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DBVCSAke.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CpzayDIw.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.B3TgrnXR.js"><!-- HEAD_svelte-1bw9n98_START --> <!-- HTML_TAG_START -->
        <script>
            (function (w, d, s, l, i) {
				w[l] = w[l] || [];
				w[l].push({ 'gtm.start': new Date().getTime(), event: 'gtm.js' });
				var f = d.getElementsByTagName(s)[0],
					j = d.createElement(s),
					dl = l != 'dataLayer' ? '&l=' + l : '';
				j.async = true;
				j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
				f.parentNode.insertBefore(j, f);
			})(window, document, 'script', 'dataLayer', 'GTM-53SQQ8DM');
        </script>
        <!-- HTML_TAG_END --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-HHT51PP7TD" data-svelte-h="svelte-guog4f"></script> <!-- HTML_TAG_START -->
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() {
            dataLayer.push(arguments);
            }
            gtag('js', new Date());
            // gtag('config', 'G-HHT51PP7TD', { debug_mode: true });
            gtag('config', 'G-HHT51PP7TD');
        </script>
        <!-- HTML_TAG_END --><!-- HEAD_svelte-1bw9n98_END --><!-- HEAD_svelte-r30au3_START --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><!-- HEAD_svelte-r30au3_END -->
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">   <div id="app" style="--min-screen-width:1300px;--min-column-width:22px;--predicted-color:#7E3AF2;" class="svelte-1tjcd38"><div id="landing" class="svelte-1tjcd38"><header style="transform: translateX(0px);" class="svelte-1tjcd38"><div class="top-bar flex w-full items-center gap-4 px-10 py-2 pb-3 svelte-1r01wg1"><div class="logo text-bold text-gray-700 svelte-1r01wg1" data-click="logo" data-svelte-h="svelte-1df1j3v">T<span class="small svelte-1r01wg1">RANSFORMER</span> E<span class="small svelte-1r01wg1">XPLAINER</span></div> <div class="inputs flex grow items-center"><div class="input-wrapper w-full svelte-1r01wg1"><div class="input-area svelte-rpzbd3" data-click="input-area"><form class="input-form svelte-rpzbd3" data-click="input-form"><div class="inline-flex rounded-lg shadow-sm input-btn-group" role="group"><button data-click="dropdown-btn" type="button"  class="select-button inline-flex shrink-0 items-center justify-center border border-s-0 border-gray-200 bg-white px-3 py-2 text-center text-xs font-medium text-gray-900 first:rounded-s-lg first:border-s last:rounded-e-lg svelte-rpzbd3">Examples<svg xmlns="http://www.w3.org/2000/svg" fill="none" color="currentColor" class="shrink-0 pointer-events-none h-4 w-4 text-gray-500" role="img" aria-label="chevron down outline" viewBox="0 0 24 24"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m8 10 4 4 4-4"></path></svg> </button> <div></div>    <div data-click="text-input" class="input-container svelte-rpzbd3 disabled" role="none"><div class="editable w-full svelte-rpzbd3"><div contenteditable="false" class="text-box svelte-rpzbd3" placeholder="Test your own input text" role="input">Data visualization empowers users to</div> <div class="predicted svelte-rpzbd3" role="none"><span class="svelte-rpzbd3"></span></div></div>  </div></div>  <button data-click="generate-btn" disabled class="generate-button rounded-lg text-center text-sm shadow-sm disabled svelte-rpzbd3" type="submit">Generate</button></form> <div class="parameters svelte-rpzbd3" data-click="input-parameters"><div class="temperature-input svelte-47a5d3" data-click="temperature-input"><div class="slider-input shrink-0 text-gray-900 temperature-slider svelte-1pcv1cp"><div class="slider-head flex w-full shrink-0 items-center justify-center"><div class="temperature-text flex items-center gap-[2px] svelte-47a5d3"><div id="temperature" class="textbook-tooltip svelte-138miuj" data-click="textbook-tooltip" role="button" tabindex="0"><div data-svelte-h="svelte-knfc80">Temperature</div> </div> </div></div> <div class="slider-container svelte-1pcv1cp"><input  class="slider svelte-1pcv1cp" type="range" min="0" max="17" step="1" value="6"> <div class="value svelte-1pcv1cp"><p>0.8</p></div></div> </div> </div> <div class="sampling-input svelte-19rf5er" data-click="input-sampling"><div class="slider-input shrink-0 text-gray-900 sampling-slider svelte-1pcv1cp"><div class="slider-head flex w-full shrink-0 items-center justify-center"><div class="sampling-type svelte-19rf5er"><div class="title flex items-center gap-[2px] svelte-19rf5er"><div id="sampling" class="textbook-tooltip svelte-138miuj" data-click="textbook-tooltip" role="button" tabindex="0"><div data-svelte-h="svelte-1brf1i7">Sampling</div> </div> </div> <div class="sampling-type-input flex svelte-19rf5er"> <label class="text-sm rtl:text-right font-medium text-gray-900 dark:text-gray-300 inline-flex items-center type-btn"><input type="radio" value="top-k" class="w-4 h-4 bg-gray-100 border-gray-300 dark:ring-offset-gray-800 focus:ring-2 me-2 dark:bg-gray-700 dark:border-gray-600 text-purple-600 focus:ring-purple-500 dark:focus:ring-purple-600" name="sampling-type" checked> Top-k</label>    <label class="text-sm rtl:text-right font-medium text-gray-900 dark:text-gray-300 inline-flex items-center type-btn"><input type="radio" value="top-p" class="w-4 h-4 bg-gray-100 border-gray-300 dark:ring-offset-gray-800 focus:ring-2 me-2 dark:bg-gray-700 dark:border-gray-600 text-purple-600 focus:ring-purple-500 dark:focus:ring-purple-600" name="sampling-type"> Top-p</label>  </div></div></div> <div class="slider-container svelte-1pcv1cp"><input  class="slider svelte-1pcv1cp" type="range" min="1" max="50" step="1" value="5"> <div class="value svelte-1pcv1cp"><p>k=5</p></div></div> </div> </div></div> </div></div></div> <div class="icons flex items-center gap-3 svelte-1r01wg1" data-svelte-h="svelte-g137ca"> <a href="https://arxiv.org/abs/2408.04619" target="_blank" data-click="pdf-btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M9 2.221V7H4.221a2 2 0 0 1 .365-.5L8.5 2.586A2 2 0 0 1 9 2.22ZM11 2v5a2 2 0 0 1-2 2H4a2 2 0 0 0-2 2v7a2 2 0 0 0 2 2 2 2 0 0 0 2 2h12a2 2 0 0 0 2-2 2 2 0 0 0 2-2v-7a2 2 0 0 0-2-2V4a2 2 0 0 0-2-2h-7Zm-6 9a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h.5a2.5 2.5 0 0 0 0-5H5Zm1.5 3H6v-1h.5a.5.5 0 0 1 0 1Zm4.5-3a1 1 0 0 0-1 1v5a1 1 0 0 0 1 1h1.376A2.626 2.626 0 0 0 15 15.375v-1.75A2.626 2.626 0 0 0 12.375 11H11Zm1 5v-3h.375a.626.626 0 0 1 .625.626v1.748a.625.625 0 0 1-.626.626H12Zm5-5a1 1 0 0 0-1 1v5a1 1 0 1 0 2 0v-1h1a1 1 0 1 0 0-2h-1v-1h1a1 1 0 1 0 0-2h-2Z" clip-rule="evenodd"></path></svg></a>  <a href="https://www.youtube.com/watch?v=ECR4oAwocjs" target="_blank" data-click="ytb-btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M21.7 8.037a4.26 4.26 0 0 0-.789-1.964 2.84 2.84 0 0 0-1.984-.839c-2.767-.2-6.926-.2-6.926-.2s-4.157 0-6.928.2a2.836 2.836 0 0 0-1.983.839 4.225 4.225 0 0 0-.79 1.965 30.146 30.146 0 0 0-.2 3.206v1.5a30.12 30.12 0 0 0 .2 3.206c.094.712.364 1.39.784 1.972.604.536 1.38.837 2.187.848 1.583.151 6.731.2 6.731.2s4.161 0 6.928-.2a2.844 2.844 0 0 0 1.985-.84 4.27 4.27 0 0 0 .787-1.965 30.12 30.12 0 0 0 .2-3.206v-1.516a30.672 30.672 0 0 0-.202-3.206Zm-11.692 6.554v-5.62l5.4 2.819-5.4 2.801Z" clip-rule="evenodd"></path></svg></a>  <a href="https://github.com/poloclub/transformer-explainer" target="_blank" data-click="github_btn"><svg class="h-6 w-6 text-gray-800 dark:text-white svelte-1r01wg1" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z" clip-rule="evenodd"></path></svg></a></div> </div></header> <main id="main" style="padding-top:0px" class="svelte-1tjcd38"><div class="flex h-full w-full items-center justify-center"><svg role="status" class="inline -mt-px animate-spin dark:text-gray-600 w-8 h-8 text-gray-300 fill-purple-600" viewBox="0 0 100 101" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M100 50.5908C100 78.2051 77.6142 100.591 50 100.591C22.3858 100.591 0 78.2051 0 50.5908C0 22.9766 22.3858 0.59082 50 0.59082C77.6142 0.59082 100 22.9766 100 50.5908ZM9.08144 50.5908C9.08144 73.1895 27.4013 91.5094 50 91.5094C72.5987 91.5094 90.9186 73.1895 90.9186 50.5908C90.9186 27.9921 72.5987 9.67226 50 9.67226C27.4013 9.67226 9.08144 27.9921 9.08144 50.5908Z" fill="currentColor"></path><path d="M93.9676 39.0409C96.393 38.4038 97.8624 35.9116 97.0079 33.5539C95.2932 28.8227 92.871 24.3692 89.8167 20.348C85.8452 15.1192 80.8826 10.7238 75.2124 7.41289C69.5422 4.10194 63.2754 1.94025 56.7698 1.05124C51.7666 0.367541 46.6976 0.446843 41.7345 1.27873C39.2613 1.69328 37.813 4.19778 38.4501 6.62326C39.0873 9.04874 41.5694 10.4717 44.0505 10.1071C47.8511 9.54855 51.7191 9.52689 55.5402 10.0491C60.8642 10.7766 65.9928 12.5457 70.6331 15.2552C75.2735 17.9648 79.3347 21.5619 82.5849 25.841C84.9175 28.9121 86.7997 32.2913 88.1811 35.8758C89.083 38.2158 91.5421 39.6781 93.9676 39.0409Z" fill="currentFill"></path></svg> </div></main></div> <div class="article h-auto w-full svelte-1tjcd38"><div id="description" class="svelte-s9hg3b"><div class="article-section svelte-s9hg3b" data-click="article-intro" data-svelte-h="svelte-1sb053z"><h1 class="svelte-s9hg3b">What is a Transformer?</h1> <p class="svelte-s9hg3b">Transformer is a neural network architecture that has fundamentally changed the approach to
			Artificial Intelligence. Transformer was first introduced in the seminal paper
			<a href="https://dl.acm.org/doi/10.5555/3295222.3295349" title="ACM Digital Library" target="_blank" class="svelte-s9hg3b">&quot;Attention is All You Need&quot;</a>
			in 2017 and has since become the go-to architecture for deep learning models, powering text-generative
			models like OpenAI&#39;s <strong>GPT</strong>, Meta&#39;s <strong>Llama</strong>, and Google&#39;s
			<strong>Gemini</strong>. Beyond text, Transformer is also applied in
			<a href="https://huggingface.co/learn/audio-course/en/chapter3/introduction" title="Hugging Face" target="_blank" class="svelte-s9hg3b">audio generation</a>,
			<a href="https://huggingface.co/learn/computer-vision-course/unit3/vision-transformers/vision-transformers-for-image-classification" title="Hugging Face" target="_blank" class="svelte-s9hg3b">image recognition</a>,
			<a href="https://elifesciences.org/articles/82819" title="eLife" class="svelte-s9hg3b">protein structure prediction</a>, and even
			<a href="https://www.deeplearning.ai/the-batch/reinforcement-learning-plus-transformers-equals-efficiency/" title="Deep Learning AI" target="_blank" class="svelte-s9hg3b">game playing</a>, demonstrating its versatility across numerous domains.</p> <p class="svelte-s9hg3b">Fundamentally, text-generative Transformer models operate on the principle of <strong>next-token prediction</strong>: given a text prompt from the user, what is the
			<em>most probable next token (a word or part of a word)</em> that will follow this input? The core
			innovation and power of Transformers lie in their use of self-attention mechanism, which allows
			them to process entire sequences and capture long-range dependencies more effectively than previous
			architectures.</p> <p class="svelte-s9hg3b">GPT-2 family of models are prominent examples of text-generative Transformers. Transformer
			Explainer is powered by the
			<a href="https://huggingface.co/openai-community/gpt2" title="Hugging Face" target="_blank" class="svelte-s9hg3b">GPT-2</a>
			(small) model which has 124 million parameters. While it is not the latest or most powerful Transformer
			model, it shares many of the same architectural components and principles found in the current
			state-of-the-art models making it an ideal starting point for understanding the basics.</p></div> <div class="article-section svelte-s9hg3b" data-click="article-overview" data-svelte-h="svelte-1ew5z4z"><h1 class="svelte-s9hg3b">Transformer Architecture</h1> <p class="svelte-s9hg3b">Every text-generative Transformer consists of these <strong>three key components</strong>:</p> <ol class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Embedding</strong>: Text input is divided into smaller units
				called tokens, which can be words or subwords. These tokens are converted into numerical
				vectors called embeddings, which capture the semantic meaning of words.</li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Transformer Block</strong> is the fundamental building block of
				the model that processes and transforms the input data. Each block includes:
				<ul class=" svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Attention Mechanism</strong>, the core component of the Transformer block. It
						allows tokens to communicate with other tokens, capturing contextual information and
						relationships between words.</li> <li class="svelte-s9hg3b"><strong>MLP (Multilayer Perceptron) Layer</strong>, a feed-forward network that operates
						on each token independently. While the goal of the attention layer is to route
						information between tokens, the goal of the MLP is to refine each token&#39;s
						representation.</li></ul></li> <li class="svelte-s9hg3b"><strong class="bold-purple svelte-s9hg3b">Output Probabilities</strong>: The final linear and softmax
				layers transform the processed embeddings into probabilities, enabling the model to make
				predictions about the next token in a sequence.</li></ol></div> <div class="article-section svelte-s9hg3b" id="embedding" data-click="article-embedding" data-svelte-h="svelte-rmkbl3"><h2 class="svelte-s9hg3b">Embedding</h2> <p class="svelte-s9hg3b">Let&#39;s say you want to generate text using a Transformer model. You add the prompt like this
			one: <code class="svelte-s9hg3b">“Data visualization empowers users to”</code>. This input needs to be converted
			into a format that the model can understand and process. That is where embedding comes in: it
			transforms the text into a numerical representation that the model can work with. To convert a
			prompt into embedding, we need to 1) tokenize the input, 2) obtain token embeddings, 3) add
			positional information, and finally 4) add up token and position encodings to get the final
			embedding. Let’s see how each of these steps is done.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/embedding.png" width="65%" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Figure <span class="attention">1</span>. Expanding the Embedding layer view, showing how the
			input prompt is converted to a vector representation. The process involves
			<span class="fig-numbering">(1)</span> Tokenization, (2) Token Embedding, (3) Positional Encoding,
			and (4) Final Embedding.</div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Step 1: Tokenization</h3> <p class="svelte-s9hg3b">Tokenization is the process of breaking down the input text into smaller, more manageable
				pieces called tokens. These tokens can be a word or a subword. The words <code class="svelte-s9hg3b">&quot;Data&quot;</code>
				and <code class="svelte-s9hg3b">&quot;visualization&quot;</code> correspond to unique tokens, while the word
				<code class="svelte-s9hg3b">&quot;empowers&quot;</code>
				is split into two tokens. The full vocabulary of tokens is decided before training the model:
				GPT-2&#39;s vocabulary has <code class="svelte-s9hg3b">50,257</code> unique tokens. Now that we split our input text into
				tokens with distinct IDs, we can obtain their vector representation from embeddings.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-token-embedding"><h3 class="svelte-s9hg3b">Step 2. Token Embedding</h3> <p class="svelte-s9hg3b">GPT-2 (small) represents each token in the vocabulary as a 768-dimensional vector; the
				dimension of the vector depends on the model. These embedding vectors are stored in a matrix
				of shape <code class="svelte-s9hg3b">(50,257, 768)</code>, containing approximately 39 million parameters! This
				extensive matrix allows the model to assign semantic meaning to each token, in the sense
				that tokens with similar usage or meaning in language are placed close together in this
				high-dimensional space, while dissimilar tokens are farther apart.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-positional-embedding"><h3 class="svelte-s9hg3b">Step 3. Positional Encoding</h3> <p class="svelte-s9hg3b">The Embedding layer also encodes information about each token&#39;s position in the input
				prompt. Different models use various methods for positional encoding. GPT-2 trains its own
				positional encoding matrix from scratch, integrating it directly into the training process.</p> </div> <div class="article-subsection svelte-s9hg3b"><h3 class="svelte-s9hg3b">Step 4. Final Embedding</h3> <p class="svelte-s9hg3b">Finally, we sum the token and positional encodings to get the final embedding
				representation. This combined representation captures both the semantic meaning of the
				tokens and their position in the input sequence.</p></div></div> <div class="article-section svelte-s9hg3b" data-click="article-transformer-block" data-svelte-h="svelte-1tij4b8"><h2 class="svelte-s9hg3b">Transformer Block</h2> <p class="svelte-s9hg3b">The core of the Transformer&#39;s processing lies in the Transformer block, which comprises
			multi-head self-attention and a Multi-Layer Perceptron layer. Most models consist of multiple
			such blocks that are stacked sequentially one after the other. The token representations
			evolve through layers, from the first block to the last one, allowing the model to build up an
			intricate understanding of each token. This layered approach leads to higher-order
			representations of the input. The GPT-2 (small) model we are examining consists of <code class="svelte-s9hg3b">12</code> such blocks.</p></div> <div class="article-section svelte-s9hg3b" id="self-attention" data-click="article-attention"><h3 class="svelte-s9hg3b" data-svelte-h="svelte-1rh5d9z">Multi-Head Self-Attention</h3> <p class="svelte-s9hg3b" data-svelte-h="svelte-rcx9z1">The self-attention mechanism enables the model to capture relationships among tokens in a
			sequence, so that each token’s representation is influenced by the others. Multiple attention
			heads allow the model to consider these relationships from different perspectives; for
			example, one head may capture short-range syntactic links while another tracks broader
			semantic context. In the following section, we will walk through how multi-head self-attention
			is computed step by step.</p> <div class="article-subsection-l2 svelte-s9hg3b"><h4 class="svelte-s9hg3b" data-svelte-h="svelte-8bip7u">Step 1: Query, Key, and Value Matrices</h4> <div class="figure pt-10 svelte-s9hg3b"><img src="./article_assets/QKV.png" width="80%" class="svelte-s9hg3b"> <div class="text-xs svelte-s9hg3b"> <!-- HTML_TAG_START --><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mi>K</mi><msub><mi>V</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><munderover><mo>∑</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mn>768</mn></munderover><msub><mtext>Embedding</mtext><mrow><mi>i</mi><mo separator="true">,</mo><mi>d</mi></mrow></msub><mo>⋅</mo><msub><mtext>Weights</mtext><mrow><mi>d</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mtext>Bias</mtext><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">
		QKV_{ij} = ( \sum_{d=1}^{768} \text{Embedding}_{i,d} \cdot \text{Weights}_{d,j}) + \text{Bias}_j
		</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">Q</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1032em;vertical-align:-1.3021em;"></span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">768</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord text"><span class="mord">Embedding</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.242em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3802em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1302em;vertical-align:-0.3802em;"></span><span class="mord"><span class="mord text"><span class="mord">Weights</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.242em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3802em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord text"><span class="mord">Bias</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><!-- HTML_TAG_END --></div></div> <div class="figure-caption svelte-s9hg3b" data-svelte-h="svelte-1ude1u1">Figure <span class="attention">2</span>. Computing Query, Key, and Value matrices from the
				original embedding.</div> <p class="svelte-s9hg3b" data-svelte-h="svelte-w6jp73">Each token&#39;s embedding vector is transformed into three vectors:
				<span class="q-color svelte-s9hg3b">Query (Q)</span>,
				<span class="k-color svelte-s9hg3b">Key (K)</span>, and
				<span class="v-color svelte-s9hg3b">Value (V)</span>. These vectors are derived by multiplying the input
				embedding matrix with learned weight matrices for
				<span class="q-color svelte-s9hg3b">Q</span>,
				<span class="k-color svelte-s9hg3b">K</span>, and
				<span class="v-color svelte-s9hg3b">V</span>. Here&#39;s a web search analogy to help us build some intuition
				behind these matrices:</p> <ul class="svelte-s9hg3b" data-svelte-h="svelte-1igcjnc"><li class="svelte-s9hg3b"><strong class="q-color font-medium svelte-s9hg3b">Query (Q)</strong> is the search text you type in the
					search engine bar. This is the token you want to
					<em>&quot;find more information about&quot;</em>.</li> <li class="svelte-s9hg3b"><strong class="k-color font-medium svelte-s9hg3b">Key (K)</strong> is the title of each web page in the search
					result window. It represents the possible tokens the query can attend to.</li> <li class="svelte-s9hg3b"><strong class="v-color font-medium svelte-s9hg3b">Value (V)</strong> is the actual content of web pages shown.
					Once we matched the appropriate search term (Query) with the relevant results (Key), we want
					to get the content (Value) of the most relevant pages.</li></ul> <p class="svelte-s9hg3b" data-svelte-h="svelte-6hb9at">By using these QKV values, the model can calculate attention scores, which determine how
				much focus each token should receive when generating predictions.</p></div> <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-7gj8tx"><h4 class="svelte-s9hg3b">Step 2: Multi-Head Splitting</h4> <p class="svelte-s9hg3b"><span class="q-color svelte-s9hg3b">Query</span>, <span class="k-color svelte-s9hg3b">key</span>, and
				<span class="v-color svelte-s9hg3b">Value</span>
				vectors are split into multiple heads—in GPT-2 (small)&#39;s case, into
				<code class="svelte-s9hg3b">12</code> heads. Each head processes a segment of the embeddings independently, capturing
				different syntactic and semantic relationships. This design facilitates parallel learning of
				diverse linguistic features, enhancing the model&#39;s representational power.</p></div> <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-ki4rub"><h4 class="svelte-s9hg3b">Step 3: Masked Self-Attention</h4> <p class="svelte-s9hg3b">In each head, we perform masked self-attention calculations. This mechanism allows the model
				to generate sequences by focusing on relevant parts of the input while preventing access to
				future tokens.</p> <div class="figure svelte-s9hg3b"><img src="./article_assets/attention.png" width="80%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Figure <span class="attention">3</span>. Using Query, Key, and Value matrices to calculate
				masked self-attention.</div> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Dot Product</strong>: The dot product of
					<span class="q-color svelte-s9hg3b">Query</span>
					and <span class="k-color svelte-s9hg3b">Key</span> matrices determines the
					<strong>attention score</strong>, producing a square matrix that reflects the relationship
					between all input tokens.</li> <li class="svelte-s9hg3b"><strong>Scaling · Mask</strong>: The attention scores are scaled and a mask is applied to
					the upper triangle of the attention matrix to prevent the model from accessing future
					tokens, setting these values to negative infinity. The model needs to learn how to predict
					the next token without “peeking” into the future.</li> <li class="svelte-s9hg3b"><strong>Softmax · Dropout</strong>: After masking and scaling, the attention scores are
					converted into probabilities by the softmax operation, then optionally regularized with
					dropout. Each row of the matrix sums to one and indicates the relevance of every other
					token to the left of it.</li></ul></div> <div class="article-subsection-l2 svelte-s9hg3b" data-svelte-h="svelte-1uge4ya"><h4 class="svelte-s9hg3b">Step 4: Output and Concatenation</h4> <p class="svelte-s9hg3b">The model uses the masked self-attention scores and multiplies them with the
				<span class="v-color svelte-s9hg3b">Value</span> matrix to get the
				<span class="purple-color svelte-s9hg3b">final output</span>
				of the self-attention mechanism. GPT-2 has <code class="svelte-s9hg3b">12</code> self-attention heads, each capturing
				different relationships between tokens. The outputs of these heads are concatenated and passed
				through a linear projection.</p></div></div> <div class="article-section svelte-s9hg3b" id="article-activation" data-click="article-mlp" data-svelte-h="svelte-b028ae"><h3 class="svelte-s9hg3b">MLP: Multi-Layer Perceptron</h3> <div class="figure svelte-s9hg3b"><img src="./article_assets/mlp.png" width="70%" align="middle" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Figure <span class="attention">4</span>. Using MLP layer to project the self-attention
			representations into higher dimensions to enhance the model&#39;s representational capacity.</div> <p class="svelte-s9hg3b">After the multiple heads of self-attention capture the diverse relationships between the input
			tokens, the concatenated outputs are passed through the Multilayer Perceptron (MLP) layer to
			enhance the model&#39;s representational capacity. The MLP block consists of two linear
			transformations with a <a href="https://en.wikipedia.org/wiki/Rectified_linear_unit#Gaussian-error_linear_unit_(GELU)" class="svelte-s9hg3b">GELU</a> activation function in between.</p> <p class="svelte-s9hg3b">The first linear transformation expands the dimensionality of the input four-fold from <code class="svelte-s9hg3b">768</code>
			to
			<code class="svelte-s9hg3b">3072</code>. This expansion step allows the model to project the token representations
			into a higher-dimensional space, where it can capture richer and more complex patterns that
			may not be visible in the original dimension.</p> <p class="svelte-s9hg3b">The second linear transformation then reduces the dimensionality back to the original size of <code class="svelte-s9hg3b">768</code>.This compression step brings the representations back to a manageable size while retaining
			the useful nonlinear transformations introduced in the expansion step.</p> <p class="svelte-s9hg3b">Unlike the self-attention mechanism, which integrates information across tokens, the MLP
			processes tokens independently and simply maps each token representation from one space to
			another, enriching the overall model capacity.</p></div> <div class="article-section svelte-s9hg3b" id="article-prob" data-click="article-prob" data-svelte-h="svelte-1dz5899"><h2 class="svelte-s9hg3b">Output Probabilities</h2> <p class="svelte-s9hg3b">After the input has been processed through all Transformer blocks, the output is passed
			through the final linear layer to prepare it for token prediction. This layer projects the
			final representations into a <code class="svelte-s9hg3b">50,257</code>
			dimensional space, where every token in the vocabulary has a corresponding value called
			<code class="svelte-s9hg3b">logit</code>. Any token can be the next word, so this process allows us to simply rank
			these tokens by their likelihood of being that next word. We then apply the softmax function
			to convert the logits into a probability distribution that sums to one. This will allow us to
			sample the next token based on its likelihood.</p> <div class="figure py-5 svelte-s9hg3b"><img src="./article_assets/softmax.png" width="70%" class="svelte-s9hg3b"></div> <div class="figure-caption svelte-s9hg3b">Figure <span class="attention">5</span>. Each token in the vocabulary is assigned a
			probability based on the model&#39;s output logits. These probabilities determine the likelihood
			of each token being the next word in the sequence.</div> <p id="article-temperature" data-click="article-temperature" class="svelte-s9hg3b">The final step is to generate the next token by sampling from this distribution The <code class="svelte-s9hg3b">temperature</code>
			hyperparameter plays a critical role in this process. Mathematically speaking, it is a very simple
			operation: model output logits are simply divided by the
			<code class="svelte-s9hg3b">temperature</code>:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature = 1</code>: Dividing logits by one has no effect on the softmax outputs.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &lt; 1</code>: Lower temperature makes the model more confident and
				deterministic by sharpening the probability distribution, leading to more predictable
				outputs.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">temperature &gt; 1</code>: Higher temperature creates a softer probability
				distribution, allowing for more randomness in the generated text – what some refer to as
				model <em>“creativity”</em>.</li></ul> <p id="article-sampling" data-click="article-sampling" class="svelte-s9hg3b">In addition, the sampling process can be further refined using <code class="svelte-s9hg3b">top-k</code>
			and
			<code class="svelte-s9hg3b">top-p</code> parameters:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><code class="svelte-s9hg3b">top-k sampling</code>: Limits the candidate tokens to the top k tokens with the
				highest probabilities, filtering out less likely options.</li> <li class="svelte-s9hg3b"><code class="svelte-s9hg3b">top-p sampling</code>: Considers the smallest set of tokens whose cumulative
				probability exceeds a threshold p, ensuring that only the most likely tokens contribute
				while still allowing for diversity.</li></ul> <p class="svelte-s9hg3b">By tuning <code class="svelte-s9hg3b">temperature</code>, <code class="svelte-s9hg3b">top-k</code>, and <code class="svelte-s9hg3b">top-p</code>, you can
			balance between deterministic and diverse outputs, tailoring the model&#39;s behavior to your
			specific needs.</p></div> <div class="article-section svelte-s9hg3b" data-click="article-advanced-features" data-svelte-h="svelte-1a1e1vs"><h2 class="svelte-s9hg3b">Advanced Architectural Features</h2> <p class="svelte-s9hg3b">There are several advanced architectural features that enhance the performance of Transformer
			models. While important for the model&#39;s overall performance, they are not as important for
			understanding the core concepts of the architecture. Layer Normalization, Dropout, and
			Residual Connections are crucial components in Transformer models, particularly during the
			training phase. Layer Normalization stabilizes training and helps the model converge faster.
			Dropout prevents overfitting by randomly deactivating neurons. Residual Connections allows
			gradients to flow directly through the network and helps to prevent the vanishing gradient
			problem.</p> <div class="article-subsection svelte-s9hg3b" id="article-ln"><h3 class="svelte-s9hg3b">Layer Normalization</h3> <p class="svelte-s9hg3b">Layer Normalization helps to stabilize the training process and improves convergence. It
				works by normalizing the inputs across the features, ensuring that the mean and variance of
				the activations are consistent. This normalization helps mitigate issues related to internal
				covariate shift, allowing the model to learn more effectively and reducing the sensitivity
				to the initial weights. Layer Normalization is applied twice in each Transformer block, once
				before the self-attention mechanism and once before the MLP layer.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-dropout"><h3 class="svelte-s9hg3b">Dropout</h3> <p class="svelte-s9hg3b">Dropout is a regularization technique used to prevent overfitting in neural networks by
				randomly setting a fraction of model weights to zero during training. This encourages the
				model to learn more robust features and reduces dependency on specific neurons, helping the
				network generalize better to new, unseen data. During model inference, dropout is
				deactivated. This essentially means that we are using an ensemble of the trained
				subnetworks, which leads to a better model performance.</p></div> <div class="article-subsection svelte-s9hg3b" id="article-residual"><h3 class="svelte-s9hg3b">Residual Connections</h3> <p class="svelte-s9hg3b">Residual connections were first introduced in the ResNet model in 2015. This architectural
				innovation revolutionized deep learning by enabling the training of very deep neural
				networks. Essentially, residual connections are shortcuts that bypass one or more layers,
				adding the input of a layer to its output. This helps mitigate the vanishing gradient
				problem, making it easier to train deep networks with multiple Transformer blocks stacked on
				top of each other. In GPT-2, residual connections are used twice within each Transformer
				block: once before the MLP and once after, ensuring that gradients flow more easily, and
				earlier layers receive sufficient updates during backpropagation.</p></div></div> <div class="article-section svelte-s9hg3b" data-click="article-interactive-features" data-svelte-h="svelte-u65jg4"><h1 class="svelte-s9hg3b">Interactive Features</h1> <p class="svelte-s9hg3b">Transformer Explainer is built to be interactive and allows you to explore the inner workings
			of the Transformer. Here are some of the interactive features you can play with:</p> <ul class="svelte-s9hg3b"><li class="svelte-s9hg3b"><strong>Input your own text sequence</strong> to see how the model processes it and predicts
				the next word. Explore attention weights, intermediate computations, and see how the final output
				probabilities are calculated.</li> <li class="svelte-s9hg3b"><strong>Use temperature slider</strong> to control the randomness of the model’s predictions.
				Explore how you can make the model output more deterministic or more creative by changing the
				temperature value.</li> <li class="svelte-s9hg3b"><strong>Select top-k and top-p sampling methods</strong> to adjust sampling behavior during inference.
				Experiment with different values and see how the probability distribution changes and influences
				the model&#39;s predictions.</li> <li class="svelte-s9hg3b"><strong>Interact with attention maps</strong> to see how the model focuses on different tokens
				in the input sequence. Hover over tokens to highlight their attention weights and explore how
				the model captures context and relationships between words.</li></ul></div> <div class="article-section svelte-s9hg3b" data-click="article-video" data-svelte-h="svelte-1txw9zd"><h2 class="svelte-s9hg3b">Video Tutorial</h2> <div class="video-container svelte-s9hg3b"><iframe src="https://www.youtube.com/embed/ECR4oAwocjs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="svelte-s9hg3b"></iframe></div></div> <div class="article-section svelte-s9hg3b" data-click="article-implementation" data-svelte-h="svelte-194ob15"><h2 class="svelte-s9hg3b">How is Transformer Explainer Implemented?</h2> <p class="svelte-s9hg3b">Transformer Explainer features a live GPT-2 (small) model running directly in the browser.
			This model is derived from the PyTorch implementation of GPT by Andrej Karpathy&#39;s
			<a href="https://github.com/karpathy/nanoGPT" title="Github" target="_blank" class="svelte-s9hg3b">nanoGPT project</a>
			and has been converted to
			<a href="https://onnxruntime.ai/" title="ONNX" target="_blank" class="svelte-s9hg3b">ONNX Runtime</a>
			for seamless in-browser execution. The interface is built using JavaScript, with
			<a href="https://kit.svelte.dev/" title="Svelte" target="_blank" class="svelte-s9hg3b">Svelte</a>
			as a front-end framework and
			<a href="https://d3js.org/" title="D3" target="_blank" class="svelte-s9hg3b">D3.js</a>
			for creating dynamic visualizations. Numerical values are updated live following the user input.</p></div> <div class="article-section svelte-s9hg3b" data-click="article-credit" data-svelte-h="svelte-nh6uec"><h2 class="svelte-s9hg3b">Who developed the Transformer Explainer?</h2> <p class="svelte-s9hg3b">Transformer Explainer was created by

			<a href="https://aereeeee.github.io/" target="_blank" class="svelte-s9hg3b">Aeree Cho</a>,
			<a href="https://www.linkedin.com/in/chaeyeonggracekim/" target="_blank" class="svelte-s9hg3b">Grace C. Kim</a>,
			<a href="https://alexkarpekov.com/" target="_blank" class="svelte-s9hg3b">Alexander Karpekov</a>,
			<a href="https://alechelbling.com/" target="_blank" class="svelte-s9hg3b">Alec Helbling</a>,
			<a href="https://zijie.wang/" target="_blank" class="svelte-s9hg3b">Jay Wang</a>,
			<a href="https://seongmin.xyz/" target="_blank" class="svelte-s9hg3b">Seongmin Lee</a>,
			<a href="https://bhoov.com/" target="_blank" class="svelte-s9hg3b">Benjamin Hoover</a>, and
			<a href="https://poloclub.github.io/polochau/" target="_blank" class="svelte-s9hg3b">Polo Chau</a>

			at the Georgia Institute of Technology.</p></div> </div></div></div> <div class="alert svelte-1tjcd38"><div><div role="alert" dismissable class="bg-blue-50 dark:bg-gray-800 text-blue-800 dark:text-blue-400 rounded-lg border-blue-300 dark:border-blue-800 divide-blue-300 dark:divide-blue-800 p-4 gap-3 text-sm flex items-center"> <div><div class="alert-content" data-svelte-h="svelte-p9an7x">We collect anonymous data for research.
				<a href="./consent-form.pdf" class="font-semibold underline hover:text-blue-800 dark:hover:text-blue-900" target="_blank">Learn more</a></div></div>  <button type="button" class="focus:outline-none whitespace-normal m-0.5 rounded-lg focus:ring-2 p-1.5 text-blue-500 focus:ring-blue-400 hover:bg-blue-200 dark:hover:text-blue-300 ms-auto -me-1.5 -my-1.5 dark:hover:bg-gray-700" aria-label="Close"><span class="sr-only">Close</span> <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button>   </div>   </div> </div> 
			
			<script>
				{
					__sveltekit_1h75xo4 = {
						base: new URL(".", location).pathname.slice(0, -1),
						assets: "/transformer-explainer"
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.BVZbiFrz.js"),
						import("./_app/immutable/entry/app.B8GfoBYF.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data: [null,null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
